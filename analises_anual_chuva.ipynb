{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOO2BVgTkHVij7derNrExsn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcoliveira-utfpr/chuva_probabilidade_sh/blob/main/analises_anual_chuva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando bibliotecas e autorizando Drive"
      ],
      "metadata": {
        "id": "1kKrsvwa2cim"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "x60q2iOD4_73"
      },
      "outputs": [],
      "source": [
        "# Limpa a saída do terminal no Google Colab\n",
        "from google.colab import output\n",
        "output.clear()\n",
        "# Instala ou atualiza a bibliotecas\n",
        "!pip install --upgrade gspread -q\n",
        "!pip install pymannkendall -q\n",
        "# Autentica o usuário no Google Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "# Importa a biblioteca para interagir com Google Sheets\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importando bibliotecas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "%config inlineBackend.figure_formats = ['svg']\n",
        "import datetime\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import math\n",
        "from scipy import stats\n",
        "from scipy.stats import (gamma, norm, ks_2samp, beta, weibull_min, expon, lognorm)\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from scipy.stats import ksone\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pymannkendall as mk\n",
        "from scipy.stats import linregress"
      ],
      "metadata": {
        "id": "ui3lg5QbvLkZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importando e abrindo planilha do Drive"
      ],
      "metadata": {
        "id": "h6ulQr322xYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importantando planilha e abrindo***********************************************\n",
        "nome_da_planilha = 'dados_chuva_oeste'\n",
        "nome_da_aba = \"df_resultados\"\n",
        "spreasheet = gc.open(nome_da_planilha)\n",
        "worksheet = spreasheet.worksheet(nome_da_aba)\n",
        "df = pd.DataFrame(worksheet.get_all_values())\n",
        "head = df.loc[0].to_list()\n",
        "df.columns = head\n",
        "df = df[1:]\n",
        "cidade = df['Municipio']\n",
        "df = df.drop(columns=['Municipio'])\n",
        "df = df.replace({',': '.'}, regex=True)\n",
        "df = df.apply(lambda x: pd.to_numeric(x, errors = 'coerce'), axis=1)\n",
        "df['Municipio'] = cidade\n",
        "df['Ano'] = df['Ano'].astype(int)\n",
        "df['Mês'] = df['Mês'].astype(int)\n",
        "df['Dia'] = df['Dia'].astype(int)\n",
        "#filtra município desejado\n",
        "municipio = \"Santa Helena\"\n",
        "df = df.loc[df['Municipio'] == municipio]\n",
        "# Crie uma nova coluna 'data' a partir das colunas 'dia', 'mês' e 'ano'\n",
        "data = df['Ano'].astype(str) + '-' + df['Mês'].astype(str) + '-' + df['Dia'].astype(str)\n",
        "dia = []\n",
        "for i in data:\n",
        "  a = pd.to_datetime(datetime.strptime(i, '%Y-%m-%d').date())\n",
        "  dia.append(a)\n",
        "df['Data'] = dia\n",
        "df"
      ],
      "metadata": {
        "id": "102YZ_GP2yEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Agrupando chuva anual"
      ],
      "metadata": {
        "id": "2t59m2fR4B99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Precipitação pluvial total anual\n",
        "df_ano = df.groupby(['Ano']).agg({\n",
        "    'Chuva (mm)': 'sum'\n",
        "}).reset_index()\n",
        "df_ano\n",
        "#anos = list(set(df_ano['Ano'].tolist()))"
      ],
      "metadata": {
        "id": "aiZnHe_5vkd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analisando tendência anual"
      ],
      "metadata": {
        "id": "U9KXhgFg4Oht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extrair os anos e os valores de chuva\n",
        "anos = df_ano['Ano']\n",
        "chuva = df_ano['Chuva (mm)']\n",
        "\n",
        "# Regressão linear\n",
        "slope, intercept, r_value, p_value, std_err = linregress(anos, chuva)\n",
        "\n",
        "# Teste de Mann-Kendall\n",
        "mk_result = mk.original_test(chuva)\n",
        "\n",
        "# Armazenar os resultados\n",
        "result = {\n",
        "    'Slope': slope,\n",
        "    'Intercept': intercept,\n",
        "    'p-value Regressão': p_value,\n",
        "    'R²': r_value**2,\n",
        "    'Mann-Kendall S': mk_result.s,\n",
        "    'Mann-Kendall p-value': mk_result.p,\n",
        "    'Mann-Kendall Tendência': mk_result.trend\n",
        "}\n",
        "\n",
        "# Criar um DataFrame com os resultados para exibição\n",
        "df_results = pd.DataFrame([result])\n",
        "\n",
        "# Exibir os resultados\n",
        "df_results"
      ],
      "metadata": {
        "id": "fiPjtJELv-qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encontrando FDP e FDA"
      ],
      "metadata": {
        "id": "OIweiyBB46kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pegando uma série da chuva anual\n",
        "chuva_anual = df_ano['Chuva (mm)']\n",
        "\n",
        "#Transformando os dados\n",
        "for i in chuva_anual:\n",
        "  i + 1000\n",
        "\n",
        "# Crie um intervalo de valores para a precipitação\n",
        "x = np.linspace(0, max(chuva_anual), 1000)\n",
        "\n",
        "# Distribuição Normal\n",
        "mu, std = stats.norm.fit(chuva_anual)\n",
        "pdf_normal = stats.norm.pdf(x, mu, std)\n",
        "D_normal, p_value_normal = stats.kstest(chuva_anual, 'norm', args=(mu, std))\n",
        "cdf_normal = stats.norm.cdf(x, mu, std)\n",
        "\n",
        "# Distribuição Exponencial\n",
        "loc_exp, scale_exp = stats.expon.fit(chuva_anual)\n",
        "pdf_exp = stats.expon.pdf(x, loc=loc_exp, scale=scale_exp)\n",
        "D_exp, p_value_exp = stats.kstest(chuva_anual, 'expon', args=(loc_exp, scale_exp))\n",
        "cdf_exp = stats.expon.cdf(x, loc=loc_exp, scale=scale_exp)\n",
        "\n",
        "# Distribuição Gama\n",
        "shape_gama, loc_gama, scale_gama = stats.gamma.fit(chuva_anual)\n",
        "pdf_gama = stats.gamma.pdf(x, a=shape_gama, loc=loc_gama, scale=scale_gama)\n",
        "D_gama, p_value_gama = stats.kstest(chuva_anual, 'gamma', args=(shape_gama, loc_gama, scale_gama))\n",
        "cdf_gama = stats.gamma.cdf(x, a=shape_gama, loc=loc_gama, scale=scale_gama)\n",
        "\n",
        "# Distribuição Log-Normal\n",
        "shape_ln, loc_ln, scale_ln = stats.lognorm.fit(chuva_anual)\n",
        "pdf_ln = stats.lognorm.pdf(x, s=shape_ln, loc=loc_ln, scale=scale_ln)\n",
        "D_ln, p_value_ln = stats.kstest(chuva_anual, 'lognorm', args=(shape_ln, loc_ln, scale_ln))\n",
        "cdf_ln = stats.lognorm.cdf(x, s=shape_ln, loc=loc_ln, scale=scale_ln)\n",
        "\n",
        "n = len(chuva_anual)\n",
        "alpha = 0.05  # Nível de significância\n",
        "D_critical = ksone.ppf(1 - alpha / 2, n)\n",
        "\n",
        "# Crie um dicionário com os dados\n",
        "data = {\n",
        "    \"Distribuição\": [\"Normal\", \"Exponencial\", \"Gama\", \"Log-Normal\"],\n",
        "    \"P-valor\": [p_value_normal, p_value_exp, p_value_gama, p_value_ln],\n",
        "    \"Dsup\": [D_normal, D_exp, D_gama, D_ln],\n",
        "    \"Dcrítico\": [D_critical, D_critical, D_critical, D_critical], # Valor de D calculado (Dsup) tem que ser menor que D crítico.\n",
        "    \"Coeficientes\": [\n",
        "            f\"mu={mu:.1f}, std={std:.1f}\" if not np.isnan(mu) and not np.isnan(std) else \"-\",\n",
        "            f\"loc={loc_exp:.1f}, scale={scale_exp:.1f}\" if not np.isnan(loc_exp) and not np.isnan(scale_exp) else \"-\",\n",
        "            f\"shape={shape_gama:.1f}, loc={loc_gama:.1f}, scale={scale_gama:.1f}\" if not np.isnan(shape_gama) and not np.isnan(loc_gama) and not np.isnan(scale_gama) else \"-\",\n",
        "            f\"shape={shape_ln:.1f}, loc={loc_ln:.1f}, scale={scale_ln:.1f}\" if not np.isnan(shape_ln) and not np.isnan(loc_ln) and not np.isnan(scale_ln) else \"-\",\n",
        "        ]\n",
        "}\n",
        "\n",
        "# Crie o DataFrame\n",
        "result = pd.DataFrame(data)\n",
        "\n",
        "# Determine o melhor ajuste com base no nível de significância\n",
        "result[\"Melhor Ajuste\"] = \"Não siguinificativo\"  # Começa com \"Inadequado\" e é atualizado se um ajuste for adequado\n",
        "\n",
        "result.loc[result[\"P-valor\"] > alpha, \"Melhor Ajuste\"] = result.loc[result[\"P-valor\"] > alpha, \"Distribuição\"]\n",
        "\n",
        "# Exiba o DataFrame result\n",
        "result = result.sort_values(by='Dsup').reset_index()\n",
        "result = result[['Melhor Ajuste', 'P-valor', 'Dsup', 'Dcrítico','Coeficientes']]\n",
        "\n",
        "for i in chuva_anual:\n",
        "  i - 1000\n",
        "\n",
        "result"
      ],
      "metadata": {
        "id": "U1Oe9OsmwPXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Determiando precipitação provável"
      ],
      "metadata": {
        "id": "enUJiZht5Q6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nivel_probabilidade = [0.9, 0.8, 0.75, 0.5, 0.25, 0.20, 0.10]\n",
        "precipitacao_provavel = []\n",
        "\n",
        "for probabilidade in nivel_probabilidade:\n",
        "  shape_ln, loc_ln, scale_ln = stats.lognorm.fit(chuva_anual) #usando log normal\n",
        "  x = np.linspace(0, max(chuva_anual), 1000)\n",
        "  precipitacao_provavel_anual = max(0, stats.lognorm.ppf(probabilidade, shape_ln, loc_ln, scale_ln))\n",
        "  precipitacao_provavel.append(precipitacao_provavel_anual)\n",
        "  # valor de precipitação que é provável de ser igualado ou superado com a probabilidade especificada\n",
        "\n",
        "\n",
        "# Crie um DataFrame com os resultados\n",
        "colunas = [\"10%\", \"20%\", \"25%\", \"50%\", \"75%\", \"80%\",\"90%\"]\n",
        "precipitacao_provavel\n",
        "df_resultados = pd.DataFrame({\n",
        "    \"Probabilidade\": colunas,\n",
        "    \"Chuva provável (mm)\": precipitacao_provavel\n",
        "})\n",
        "df_resultados"
      ],
      "metadata": {
        "id": "0emwmdo1xCN8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}